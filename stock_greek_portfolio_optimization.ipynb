{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31bcc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as si\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from scipy import optimize\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from typing import Dict, Callable, List, Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99422537",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf = {\n",
    "    \"start\": \"2020-01-01\",\n",
    "    \"end\": \"2025-01-01\",\n",
    "    \"tickers\": [\"NVDA\", \"TSLA\", \"LMT\", \"AAPL\", \"MSFT\", \"SPY\"],\n",
    "    \"trend\": None,\n",
    "    \"stl_period\": 21,\n",
    "    \"robust\": True,\n",
    "    \"market_ticker\": \"^GSPC\",\n",
    "    \"rfr\": 0.04,\n",
    "    \"w_delta\": 21,\n",
    "    \"w_vol\": 21,\n",
    "    \"delta_smooth_method\": \"mean\",\n",
    "    \"vix_ticker\": \"^VIX\",\n",
    "    \"gamma_pow_transform_method\": \"Identity\",\n",
    "    \"vanna_log_transform_lambda\": 5,\n",
    "    \"charm_tanh_sign_alpha\": 0.5,\n",
    "    \"trend_power_transform_method\": \"Power\",\n",
    "    \"weight_cons\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0fe128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(stock_tickers:List[str], market_ticker:str,  vix_ticker: str, start:str, end:str):\n",
    "  tickers=stock_tickers + [market_ticker, vix_ticker]\n",
    "  data = yf.download(tickers=tickers, start=start, end=end, group_by=\"ticker\")\n",
    "  return data, tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d328c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, tickers = get_data(stock_tickers=cnf[\"tickers\"], market_ticker=cnf[\"market_ticker\"], vix_ticker=cnf[\"vix_ticker\"], start=cnf[\"start\"], end=cnf[\"end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d78a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_decomposition_metrics(log_returns: pd.DataFrame|np.ndarray,\n",
    "                            period: int|None=None, trend: int|None=None,\n",
    "                            robust: bool=True) -> pd.DataFrame:\n",
    "  if not isinstance(log_returns, pd.DataFrame) and period is None:\n",
    "    raise ValueError(\"If log_returns is not DataFrame, period should be specified\")\n",
    "\n",
    "  stl = STL(log_returns[1:,], period=period, robust=robust, trend=trend)\n",
    "  res = stl.fit()\n",
    "\n",
    "  return res.seasonal, res.trend\n",
    "\n",
    "def compute_realized_vol(df: pd.DataFrame,tickers:\n",
    "                         List[str], lambda_: int|None=None,\n",
    "                         window: int|None=21) -> pd.Series:\n",
    "  df = df.copy()\n",
    "\n",
    "  for ticker in tickers:\n",
    "    print(f\"-----{ticker}-----\")\n",
    "    df[(ticker,\"LogRet\")] = \\\n",
    "        np.log(df[(ticker,'Close')]).diff()\n",
    "\n",
    "    if lambda_:\n",
    "      df[(ticker,\"RealizedVol\")] = \\\n",
    "          df[(ticker,\"LogRet\")].emw((1-lambda_)).std() * np.sqrt(252)\n",
    "\n",
    "    elif window:\n",
    "      df[(ticker,\"RealizedVol\")] = \\\n",
    "            df[(ticker,\"LogRet\")].rolling(window).std() * np.sqrt(252)\n",
    "\n",
    "  return df\n",
    "\n",
    "def get_estimation(x:pd.DataFrame, y:pd.Series, window:int) -> pd.Series:\n",
    "    x = x.fillna(0)\n",
    "    deltas, gammas, vannas, vegas, index = [], [], [], [], []\n",
    "\n",
    "    for i in range(window, len(y)+1):\n",
    "        x_window = x.iloc[i-window:i]\n",
    "        y_window = y.iloc[i-window:i]\n",
    "\n",
    "        model = sm.OLS(y_window, sm.add_constant(x_window)).fit()\n",
    "\n",
    "        deltas.append(model.params['mkt'])\n",
    "        gammas.append(2 * model.params['mkt_sq'])\n",
    "        vannas.append(model.params['mkt_interaction'])\n",
    "        vegas.append(model.params['vix'])\n",
    "        index.append(y.index[i-1])\n",
    "\n",
    "    return (\n",
    "        pd.Series(deltas, index=index),\n",
    "        pd.Series(gammas, index=index),\n",
    "        pd.Series(vannas, index=index),\n",
    "        pd.Series(vegas, index=index),\n",
    "    )\n",
    "\n",
    "def get_sigma_hat(r_i: pd.Series, window: int=21):\n",
    "  return r_i.ewm(span=window).std()\n",
    "\n",
    "def get_charm(deltas: List[float], L:int=5):\n",
    "  charm = deltas.rolling(L).mean()\n",
    "  return charm\n",
    "\n",
    "def apply_greeks(market_returns: pd.DataFrame, stock_returns: pd.DataFrame,\n",
    "                 vix: pd.DataFrame, sigma: pd.DataFrame, window: int= 21, L:int=5):\n",
    "    vix = vix.reindex(stock_returns.index)\n",
    "    sigma_diff = sigma.diff().fillna(0)\n",
    "\n",
    "    X = pd.DataFrame({\n",
    "        'mkt': market_returns,\n",
    "        'mkt_sq': market_returns**2,\n",
    "        'mkt_interaction': market_returns * sigma_diff,\n",
    "        \"vix\": vix\n",
    "    }, index=market_returns.index)\n",
    "\n",
    "    y = stock_returns\n",
    "    delta, gamma, vanna, vega = get_estimation(window=window, x=X, y=y)\n",
    "    charm = get_charm(delta)\n",
    "\n",
    "    return delta, gamma, vanna, vega, charm\n",
    "\n",
    "def apply_scaler(df:pd.DataFrame):\n",
    "  scaler = RobustScaler()\n",
    "  columns = df.columns\n",
    "  df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "  for k, v in zip(columns, df_scaled.T):\n",
    "    df[k] = v\n",
    "\n",
    "  return df\n",
    "\n",
    "def apply_inverse_logistic_penalty(\n",
    "    feature:pd.Series, a:int, window:int, method:str):\n",
    "  if method == \"mean\":\n",
    "    t = feature.rolling(window=window, min_periods=1).mean()\n",
    "  elif method == \"median\":\n",
    "    t = feature.rolling(window=window, min_periods=1).median()\n",
    "  else:\n",
    "    t = 0\n",
    "\n",
    "  z = a*(feature-t)\n",
    "  return 1/(1+np.exp(z))\n",
    "\n",
    "def apply_power_transform(feature:pd.Series, method:str=\"Identity\", power:float|int=2):\n",
    "  x = np.array(feature, dtype=float)\n",
    "\n",
    "  if method == \"Identity\":\n",
    "    return x\n",
    "  elif method == \"Sqrt\":\n",
    "    return np.sqrt(np.maximum(x, 0))\n",
    "  elif method == \"Power\":\n",
    "    return np.power(x, power)\n",
    "  elif method == \"Reciprocal\":\n",
    "    return 1 / (x + 1e-8)\n",
    "  elif method == \"Log\":\n",
    "    return np.log(x + 1e-8)\n",
    "  else:\n",
    "    raise ValueError(f\"Unknown transform method {method}\")\n",
    "\n",
    "def apply_tanh_transform(feature: pd.Series, alpha:float=0.5) -> pd.Series:\n",
    "  return np.sign(feature) * np.tanh(alpha * np.abs(feature))\n",
    "\n",
    "def apply_log_transform(feature: pd.Series, l:int=5) -> pd.Series:\n",
    "  return np.log1p(l*np.abs(feature))\n",
    "\n",
    "def apply_softplus(feature: pd.Series) -> pd.Series:\n",
    "  return np.log1p(np.exp(np.clip(feature, -50, 50)))\n",
    "\n",
    "def apply_signed_fractional_power_transformation(\n",
    "    feature: pd.Series, power:int=0.7) -> pd.Series:\n",
    "  return np.sign(feature) * np.abs(feature)**power\n",
    "\n",
    "def normalize(feature_df:pd.Series) -> pd.Series:\n",
    "  wins = feature_df.clip(\n",
    "      lower = feature_df.quantile(0.01),\n",
    "      upper = feature_df.quantile(0.99)\n",
    "  )\n",
    "\n",
    "  med = wins.median()\n",
    "  iqr = wins.quantile(0.75) - wins.quantile(0.25)\n",
    "\n",
    "  zscore = (wins - med) / iqr\n",
    "\n",
    "  return zscore\n",
    "\n",
    "def scale(df: pd.DataFrame, a:int=1, window:int=5, method: str|None=None,\n",
    "          l_gamma:str=\"Identity\", l_vanna:int=5, tanh_sign_alpha:float=0.5,\n",
    "          trend_method:str=\"Power\") -> pd.DataFrame:\n",
    "  df_scaled = apply_scaler(df=df)\n",
    "\n",
    "  df_scaled['Delta'] = apply_inverse_logistic_penalty(feature=df_scaled['Delta'], a=a, window=window, method=method)\n",
    "  df_scaled['Gamma'] = apply_power_transform(feature=df_scaled['Gamma'], method=l_gamma)\n",
    "  df_scaled['Vanna'] = apply_log_transform(feature=df_scaled['Vanna'], l=l_vanna)\n",
    "  df_scaled['Vega'] = apply_log_transform(feature=df_scaled['Vega'], l=l_vanna)\n",
    "  df_scaled['Charm'] = apply_tanh_transform(feature=df_scaled['Charm'], alpha=tanh_sign_alpha)\n",
    "  df_scaled['Season'] = apply_softplus(feature=df_scaled['Season'])\n",
    "  df_scaled['Trend'] = apply_signed_fractional_power_transformation(feature=df_scaled['Trend'])\n",
    "\n",
    "  for col in df_scaled.columns:\n",
    "    df_scaled[col] = normalize(df_scaled[col])\n",
    "\n",
    "  return df_scaled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e38dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = compute_realized_vol(data, tickers)\n",
    "sigma_hat = get_sigma_hat(data[cnf[\"market_ticker\"]][\"LogRet\"],\n",
    "                          window=cnf['w_vol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e43b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_featureset(data:pd.DataFrame, market_data: pd.DataFrame,\n",
    "                 vix: pd.DataFrame, tickers:List[str], sigma: pd.Series):\n",
    "  composite_df = []\n",
    "  for ticker in tickers:\n",
    "    print(f\"-----{ticker}-----\")\n",
    "    tmp_data = data[ticker]\n",
    "    season, trend  = apply_decomposition_metrics(tmp_data[\"LogRet\"],\n",
    "                                                 period=cnf[\"stl_period\"])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Trend\": trend,\n",
    "        \"Season\": season\n",
    "    }, index=tmp_data.index)\n",
    "\n",
    "    greeks = apply_greeks(\n",
    "        market_returns=market[\"LogRet\"], stock_returns=tmp_data[\"LogRet\"],\n",
    "        vix=vix, sigma=sigma_hat, window=cnf['w_delta']\n",
    "    )\n",
    "\n",
    "    for k, v in zip([\"Delta\", \"Gamma\", \"Vanna\", \"Vega\", \"Charm\"], greeks):\n",
    "      df[k] = v\n",
    "    df = df.dropna()\n",
    "    df = scale(df=df, method=cnf[\"delta_smooth_method\"],\n",
    "              l_gamma=cnf[\"gamma_pow_transform_method\"],\n",
    "              l_vanna=cnf[\"vanna_log_transform_lambda\"],\n",
    "              tanh_sign_alpha=cnf[\"charm_tanh_sign_alpha\"],\n",
    "              trend_method = cnf[\"trend_power_transform_method\"]\n",
    "    )\n",
    "    composite_df.append(df)\n",
    "\n",
    "  output = pd.concat(\n",
    "      composite_df,\n",
    "      keys=tickers,\n",
    "      names=[\"Tickers\", \"Dates\"]\n",
    "  )\n",
    "\n",
    "  return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae7d26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "market = data[\"^GSPC\"]\n",
    "vix = data[(\"^VIX\", \"Close\")]\n",
    "df = data.drop([\"^GSPC\", \"^VIX\"], axis=1)\n",
    "\n",
    "composite_df = generate_featureset(df, market, vix, sigma=sigma_hat, tickers=cnf[\"tickers\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40027e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = composite_df.columns.tolist()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c500b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoringEngine:\n",
    "  def __init__(self, features: List[str], composite_df: pd.DataFrame):\n",
    "    self.features = features\n",
    "    self.composite_df = composite_df\n",
    "\n",
    "  def softplus(self, x: np.ndarray, coefs: np.ndarray) -> np.ndarray:\n",
    "    return np.log1p(np.exp(x.values.dot(coefs)))\n",
    "\n",
    "  def compute_scores(self, coefs: np.ndarray, return_scores: bool=False):\n",
    "    self.S = {}\n",
    "    self.tickers = []\n",
    "    for ticker in self.composite_df.index.levels[0]:\n",
    "      self.tickers.append(ticker)\n",
    "      df_t = self.composite_df.loc[ticker]\n",
    "      self.S[ticker] = self.softplus(df_t, coefs)\n",
    "\n",
    "    if not isinstance(self.S, pd.Series):\n",
    "      self.S = pd.DataFrame(self.S, index=df_t.index)\n",
    "    if return_scores:\n",
    "      return self.S if not self.S.empty else None\n",
    "\n",
    "  def compute_weights(self, cons: Dict[str, float]|None=None, scores: pd.DataFrame|None=None):\n",
    "    if cons is not None:\n",
    "      allowed_keys = [\"bounds\", \"vol_target\"]\n",
    "      for k, v in cons.items():\n",
    "        if k not in allowed_keys:\n",
    "          raise ValueError(f\"Unknown constraint {k}\")\n",
    "\n",
    "    if self.S.empty and scores is None:\n",
    "      raise ValueError(\"Scores not computed\")\n",
    "\n",
    "    scores = self.S # if scores is None else scores\n",
    "    W_i = scores.div(scores.sum(axis=1), axis=0)\n",
    "    return W_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f21c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_init = np.array([\n",
    "    0.8,   # Delta weight\n",
    "    0.3,   # Gamma weight\n",
    "    0.4,   # Vanna weight\n",
    "    0.5,   # Vega weight\n",
    "    0.2,   # Charm weight\n",
    "    1.0,   # Trend weight\n",
    "    0.6    # Seasonality weight\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccec424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class OptimizationConfig:\n",
    "  risk_aversion: float = 5.0\n",
    "  l2_reg: float = 0.001\n",
    "  turnover_penalty: float = 0.01\n",
    "  bounds: Optional[tuple] = (0.0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioObjective:\n",
    "  def __init__(self, scorer: ScoringEngine,\n",
    "               returns_df: pd.DataFrame,\n",
    "               config: OptimizationConfig):\n",
    "    self.scorer = scorer\n",
    "    self.returns = returns_df\n",
    "    self.config = config\n",
    "\n",
    "  def portfolio_returns(self, theta:np.ndarray)->pd.Series:\n",
    "    scores = self.scorer.compute_scores(theta)\n",
    "    weights = self.scorer.compute_weights()\n",
    "\n",
    "    weights = weights.shift(1).dropna()\n",
    "    rets = self.returns.loc[weights.index]\n",
    "    return (weights * rets).sum(axis=1)\n",
    "\n",
    "  def soft_abs(self, x: np.ndarray, eps: float=1e-8) -> np.ndarray:\n",
    "    return np.sqrt(x.pow(2) + eps)\n",
    "\n",
    "  def smooth_huber(self, x: np.ndarray, delta: float=0.005)-> np.ndarray:\n",
    "    return delta**2 * (np.sqrt(1+(x/delta)**2)-1)\n",
    "\n",
    "  def loss(self, theta:np.ndarray) -> float:\n",
    "    rp = self.portfolio_returns(theta)\n",
    "    mean = rp.mean()\n",
    "    var = rp.var()\n",
    "    shape_surrogate = mean - self.config.risk_aversion * var\n",
    "\n",
    "    reg = self.config.l2_reg * np.sum(theta ** 2)\n",
    "\n",
    "    scores = self.scorer.compute_scores(theta)\n",
    "    weights = self.scorer.compute_weights(scores, self.config.bounds)\n",
    "    turnover = self.smooth_huber(weights.diff()).sum(axis=1).mean()\n",
    "\n",
    "    penalty = self.config.turnover_penalty * turnover\n",
    "\n",
    "    return -(shape_surrogate - reg - penalty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3491bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThetaOptimizer:\n",
    "  def __init__(self, obj: PortfolioObjective):\n",
    "    self.obj = obj\n",
    "    self.theta_opt = None\n",
    "\n",
    "  def optimize(self, theta_init: Optional[np.ndarray]=None,\n",
    "               method: str=\"L-BFGS-B\") -> np.ndarray:\n",
    "    n = len(self.obj.scorer.features)\n",
    "    if theta_init is None:\n",
    "      theta_init = np.zeros(shape=len(features))\n",
    "\n",
    "    results = optimize.minimize(\n",
    "        fun=self.obj.loss,\n",
    "        x0=theta_init,\n",
    "        method=method,\n",
    "        options={\n",
    "            \"maxiter\": 10000\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if not results.success:\n",
    "      raise RuntimeError(\"Optimization Failed\")\n",
    "\n",
    "    self.theta_opt = results.x\n",
    "    return self.theta_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae6aa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_df = data.xs(\"Close\", axis=1, level=1).pct_change().dropna()\n",
    "diff_len = len(returns_df) - len(composite_df.loc[cnf[\"tickers\"][0]])\n",
    "returns_df = returns_df.iloc[diff_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0c1f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = ScoringEngine(features, composite_df)\n",
    "\n",
    "config = OptimizationConfig(\n",
    "    risk_aversion=5,\n",
    "    l2_reg=0.001,\n",
    "    turnover_penalty=0.01,\n",
    "    bounds=(0.0, 0.5)\n",
    ")\n",
    "\n",
    "objective = PortfolioObjective(scorer, returns_df, config)\n",
    "optimizer = ThetaOptimizer(objective)\n",
    "\n",
    "theta_star = optimizer.optimize()\n",
    "print(\"Optimal theta:\", theta_star)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4899b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scorer.compute_scores(theta_star)\n",
    "weights = scorer.compute_weights(scores)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f71c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softplus(x):\n",
    "    return np.log1p(np.exp(x))\n",
    "    \n",
    "def backtest_with_leverage(\n",
    "    weights: pd.DataFrame,\n",
    "    returns: pd.DataFrame,\n",
    "    leverage: float | None = 1.0,\n",
    "    vol_target: float | None = None,\n",
    "    vol_lookback: int = 20,\n",
    "    transaction_cost: float = 0.0,\n",
    "    freq: int = 20\n",
    "):\n",
    "    weights = weights.shift(1).dropna()\n",
    "    base_ret = (weights * returns).sum(axis=1)\n",
    "\n",
    "    if vol_target is not None:\n",
    "        rolling_vol = base_ret.rolling(vol_lookback).std() * np.sqrt(freq)\n",
    "        leverage_t = vol_target / rolling_vol\n",
    "        leverage_t = leverage_t.clip(0, 5)  # safety cap\n",
    "    else:\n",
    "        leverage_t = pd.Series(leverage, index=base_ret.index)\n",
    "    gross_ret = leverage_t * base_ret\n",
    "    dollar_weights = weights.mul(leverage_t, axis=0)\n",
    "    turnover = dollar_weights.diff().abs().sum(axis=1)\n",
    "    net_ret = gross_ret - transaction_cost * turnover\n",
    "    gross_equity = (1 + gross_ret).cumprod()\n",
    "    net_equity = (1 + net_ret).cumprod()\n",
    "    results = pd.DataFrame({\n",
    "        \"base_return\": base_ret,\n",
    "        \"leverage\": leverage_t,\n",
    "        \"gross_return\": gross_ret,\n",
    "        \"net_return\": net_ret,\n",
    "        \"turnover\": turnover,\n",
    "        \"gross_equity\": gross_equity,\n",
    "        \"net_equity\": net_equity\n",
    "    })\n",
    "\n",
    "    return results\n",
    "\n",
    "def performance_summary_with_leverage(results, freq=252):\n",
    "    def stats(r):\n",
    "        sharpe = np.sqrt(freq) * r.mean() / r.std()\n",
    "        vol = np.sqrt(freq) * r.std()\n",
    "        cagr = (1 + r).prod() ** (freq / len(r)) - 1\n",
    "        return sharpe, vol, cagr\n",
    "\n",
    "    sharpe_g, vol_g, cagr_g = stats(results[\"gross_return\"])\n",
    "    sharpe_n, vol_n, cagr_n = stats(results[\"net_return\"])\n",
    "\n",
    "    max_dd = (results[\"net_equity\"] /\n",
    "              results[\"net_equity\"].cummax() - 1).min()\n",
    "    roi = results[\"net_equity\"].iloc[-1] / results[\"net_equity\"].iloc[0]\n",
    "\n",
    "    return {\n",
    "        \"ROI\": roi,\n",
    "        \"Gross Sharpe\": sharpe_g,\n",
    "        \"Net Sharpe\": sharpe_n,\n",
    "        \"Gross Vol\": vol_g,\n",
    "        \"Net Vol\": vol_n,\n",
    "        \"Gross CAGR\": cagr_g,\n",
    "        \"Net CAGR\": cagr_n,\n",
    "        \"Max Drawdown\": max_dd,\n",
    "        \"Avg Turnover\": results[\"turnover\"].mean(),\n",
    "        \"Avg Leverage\": results[\"leverage\"].mean()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2a019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = backtest_with_leverage(\n",
    "    weights=weights,\n",
    "    returns=returns_df,\n",
    "    leverage=2.0,\n",
    "    transaction_cost=0.002,\n",
    "    freq=22\n",
    ")\n",
    "\n",
    "performance_summary_with_leverage(results, freq=22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

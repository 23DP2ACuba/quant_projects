{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5205290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import statsmodels.api as sms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "assets = [\"TSLA\", \"PLTR\", \"NVDA\"]\n",
    "START = \"2021-01-01\"\n",
    "END = \"2025-01-01\"\n",
    "WINDOW=252\n",
    "\n",
    "data = yf.download(assets,start = START, end=END)\n",
    "portfolio_returns = data[\"Close\"].pct_change().dropna()\n",
    "return_cumprod = portfolio_returns.add(1).cumprod().sub(1) * 100\n",
    "correlation = portfolio_returns.corr()\n",
    "sns.heatmap(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d381f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# -------- CONFIG ----------\n",
    "n = 7\n",
    "seq_len = 200\n",
    "rebalance_step = 1\n",
    "WINDOW = 30\n",
    "n_return = 5\n",
    "BATCH_SIZE = 1\n",
    "LR = 5e-5\n",
    "EMBD_SIZE = 8\n",
    "NUM_HEADS = 2\n",
    "DIM_FFN = 1024\n",
    "DROPOUT = 0\n",
    "CONV1D_EMBD = False\n",
    "KERNEL_SIZE = 5\n",
    "GAMMA = 0.9\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "class SharpeOptim:\n",
    "    def __init__(self, rfr: float = 0.009):\n",
    "        self.rfr = rfr\n",
    "\n",
    "    def neg_sharpe(self, weights):\n",
    "        pf_ret = np.dot(weights, self.mean_returns)\n",
    "        pf_vol = np.sqrt(np.dot(weights.T, np.dot(self.cov_mtx, weights)))\n",
    "        if pf_vol == 0:\n",
    "            return 1e6\n",
    "        return -(pf_ret - self.rfr) / pf_vol\n",
    "\n",
    "    def max_sharpe(self, window_returns: pd.DataFrame):\n",
    "        n_assets = window_returns.shape[1]\n",
    "        self.mean_returns = window_returns.mean(axis=0).values\n",
    "        self.cov_mtx = window_returns.cov().values + np.eye(n_assets) * 1e-8\n",
    "\n",
    "        cons = ({\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1})\n",
    "        bounds = tuple((0, 1) for _ in range(n_assets))\n",
    "        init_guess = np.array(n_assets * [1.0 / n_assets])\n",
    "\n",
    "        result = minimize(self.neg_sharpe, init_guess, method=\"SLSQP\",\n",
    "                          bounds=bounds, constraints=cons)\n",
    "\n",
    "        weights = result.x\n",
    "        weights = np.where(weights < 0.05, 0, weights)\n",
    "        return weights / weights.sum()\n",
    "\n",
    "# --------------------------\n",
    "# Rolling / Sliding window\n",
    "# --------------------------\n",
    "opt = SharpeOptim(rfr=0.009)\n",
    "\n",
    "weights_history = {}\n",
    "df = data[\"Close\"]\n",
    "dates = df.index[n:]\n",
    "for i in range(0, len(dates), rebalance_step):\n",
    "    end_date = dates[i]\n",
    "    start_loc = df.index.get_loc(end_date) - n\n",
    "    start_date = df.index[start_loc]\n",
    "\n",
    "    window = df.loc[start_date:end_date].pct_change().dropna()\n",
    "\n",
    "    w = opt.max_sharpe(window)\n",
    "    weights_history[end_date] = w\n",
    "    r = i\n",
    "\n",
    "weights = pd.DataFrame(weights_history).T\n",
    "weights.columns = df.columns\n",
    "\n",
    "arrays = [\n",
    "    [\"Target\"]*len(assets),\n",
    "    assets\n",
    "    ]\n",
    "\n",
    "columns = pd.MultiIndex.from_arrays(arrays, names=[\"Price\", \"Ticker\"])\n",
    "weights_df = pd.DataFrame(weights.values,\n",
    "                  index=weights.index,\n",
    "                  columns=columns)\n",
    "\n",
    "data = pd.concat([data, weights_df], axis=1).shift(-n)\n",
    "\n",
    "data[\"Target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba86206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from itertools import combinations\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ModelSelector:\n",
    "  def __init__(self, data):\n",
    "    data.dropna(inplace=True)\n",
    "    self.data = data\n",
    "\n",
    "  def create_features(self):\n",
    "    all_pairs = list(combinations(assets, 2))\n",
    "    features_list = []\n",
    "\n",
    "    for stock_1, stock_2 in all_pairs:\n",
    "        print(f\"Processing pair: {stock_1} - {stock_2}\")\n",
    "\n",
    "        alpha = [np.nan] * WINDOW\n",
    "        beta = [np.nan] * WINDOW\n",
    "\n",
    "        for i in range(WINDOW, len(data)):\n",
    "            past_data = data[\"Close\"].iloc[i-WINDOW:i]\n",
    "            x = past_data[stock_1].values\n",
    "            y = past_data[stock_2].values\n",
    "            x = sm.add_constant(x)\n",
    "            model = sm.OLS(y, x).fit()\n",
    "            alpha.append(model.params[0])\n",
    "            beta.append(model.params[1])\n",
    "\n",
    "        rolling_params = pd.DataFrame({\"alpha\": alpha, \"beta\": beta}, index=data.index)\n",
    "\n",
    "        spread = data[\"Close\"][stock_2] - (rolling_params[\"alpha\"] + rolling_params[\"beta\"]*data[\"Close\"][stock_1])\n",
    "\n",
    "        rolling_mean = spread.rolling(WINDOW).mean()\n",
    "        rolling_std = spread.rolling(WINDOW).std()\n",
    "        z_score = (spread - rolling_mean) / rolling_std\n",
    "        n_day_return = data[\"Close\"][stock_2].pct_change(n_return)\n",
    "\n",
    "        pair_features = pd.DataFrame({\n",
    "            f\"{stock_1}_{stock_2}_spread\": spread,\n",
    "            f\"{stock_1}_{stock_2}_rolling_mean\": rolling_mean,\n",
    "            f\"{stock_1}_{stock_2}_rolling_std\": rolling_std,\n",
    "            f\"{stock_1}_{stock_2}_z_score\": z_score,\n",
    "            f\"{stock_1}_{stock_2}_return_{n_return}d\": n_day_return\n",
    "        }, index=data.index)\n",
    "\n",
    "        features_list.append(pair_features)\n",
    "\n",
    "    self.spread_data = pd.concat(features_list, axis=1)\n",
    "\n",
    "    self.spread_data.dropna(inplace = True)\n",
    "    print(self.spread_data.columns)\n",
    "\n",
    "  def preprocessing(self):\n",
    "    self.create_features()\n",
    "    to_drop = []\n",
    "    for asset in assets:\n",
    "        to_drop.append((\"Target\", asset))\n",
    "\n",
    "    y = self.data[\"Target\"].reindex(self.spread_data.index).values\n",
    "    x = self.spread_data\n",
    "\n",
    "    self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
    "        x, y, test_size=0.2, shuffle=True\n",
    "    )\n",
    "    scaler = StandardScaler()\n",
    "    self.x_train = scaler.fit_transform(self.x_train)\n",
    "    self.x_test = scaler.transform(self.x_test)\n",
    "\n",
    "  def regressor(self):\n",
    "    param_grid = {\n",
    "        \"estimator__n_estimators\": [200, 300, 500],\n",
    "        \"estimator__max_depth\": [5, 10, 15],\n",
    "        \"estimator__min_samples_split\": [2, 5, 10],\n",
    "        \"estimator__min_samples_leaf\": [1, 2, 3, 5],\n",
    "        \"estimator__max_features\": [\"sqrt\", \"log2\"]\n",
    "    }\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=MultiOutputRegressor(RandomForestRegressor(random_state=42)),\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=10,\n",
    "        scoring=\"r2\",\n",
    "        cv=3,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    self.reg = search\n",
    "\n",
    "  def train(self):\n",
    "    self.reg.fit(self.x_train, self.y_train)\n",
    "    y_pred = self.reg.predict(self.x_test)\n",
    "    y_pred = np.clip(y_pred, 0, 1)\n",
    "    y_pred = y_pred / y_pred.sum(axis=1, keepdims=True)\n",
    "\n",
    "    print(\"Best params:\", self.reg.best_params_)\n",
    "    print(r2_score(self.y_test, y_pred))\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "      print(f\"pred: {y_pred[i]}, act: {self.y_test[i]}\")\n",
    "\n",
    "    return self.reg\n",
    "\n",
    "\n",
    "model_selector = ModelSelector(data)\n",
    "model = model_selector.preprocessing()\n",
    "model = model_selector.regressor()\n",
    "model = model_selector.train()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
